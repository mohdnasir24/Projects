{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "\n",
    "Based on the provided immigration data for usa. we will achieve to provide data to analyse following metrics\n",
    "* Age group of travellers\n",
    "* Count of traveller during the year\n",
    "* Effect on temperature by immigration\n",
    "* Effect on race,population and demographics of port of entry cities\n",
    "* Count of travellers by different visa type\n",
    "* Average footfall by airports\n",
    "* Travellers yearly and monthly trends\n",
    "\n",
    "Following data dictionaries will be used to enrich data\n",
    "\n",
    "* countries.csv : table containing country codes based on I94_SAS_Labels_Descriptions.SAS file \n",
    "* i94portCodes.csv: table containing city codes based on I94_SAS_Labels_Descriptions.SAS file \n",
    "* visa_type.csv : table containing visa code and visa type desc based on I94_SAS_Labels_Descriptions.SAS file \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format, dayofweek\n",
    "from pyspark.sql.types import StructType as R, StructField as Fld, DoubleType as Dbl, StringType as Str, IntegerType as Int, DateType as Date, LongType as Long, TimestampType as Ts\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### First read immigration sample data to see all the columns and get a high level overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = 'immigration_data_sample.csv'\n",
    "df_immig = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr    ...     entdepu  matflag  biryear   dtaddto  gender  \\\n",
       "0      1.0      HI    ...         NaN        M   1955.0  07202016       F   \n",
       "1      1.0      TX    ...         NaN        M   1990.0  10222016       M   \n",
       "2      1.0      FL    ...         NaN        M   1940.0  07052016       M   \n",
       "3      1.0      CA    ...         NaN        M   1991.0  10272016       M   \n",
       "4      3.0      NY    ...         NaN        M   1997.0  07042016       F   \n",
       "\n",
       "  insnum airline        admnum  fltno  visatype  \n",
       "0    NaN      JL  5.658267e+10  00782        WT  \n",
       "1    NaN     *GA  9.436200e+10  XBLNG        B2  \n",
       "2    NaN      LH  5.578047e+10  00464        WT  \n",
       "3    NaN      QR  9.478970e+10  00739        B2  \n",
       "4    NaN     NaN  4.232257e+10   LAND        WT  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immig.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Check temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "df_temp = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Ã…rhus   \n",
       "1  1743-12-01                 NaN                            NaN  Ã…rhus   \n",
       "2  1744-01-01                 NaN                            NaN  Ã…rhus   \n",
       "3  1744-02-01                 NaN                            NaN  Ã…rhus   \n",
       "4  1744-03-01                 NaN                            NaN  Ã…rhus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Check i94 Port data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = 'i94portCodes.csv'\n",
    "df_i94port = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>location</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONS CACHE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEW STATION PT LAY DEW</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code                  location state\n",
       "0  ALC                     ALCAN    AK\n",
       "1  ANC                 ANCHORAGE    AK\n",
       "2  BAR  BAKER AAF - BAKER ISLAND    AK\n",
       "3  DAC             DALTONS CACHE    AK\n",
       "4  PIZ    DEW STATION PT LAY DEW    AK"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_i94port.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Check demographics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = 'us-cities-demographics.csv'\n",
    "df_demographics = pd.read_csv(fname,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### create countries dictionary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = 'countries.csv'\n",
    "df_countries = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code      country\n",
       "0   582      MEXICO \n",
       "1   236  AFGHANISTAN\n",
       "2   101      ALBANIA\n",
       "3   316      ALGERIA\n",
       "4   102      ANDORRA"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_countries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### check airport data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = 'airport-codes_csv.csv'\n",
    "df_airports = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Read Full immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()\n",
    "\n",
    "df_immigration_stats = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|  6.0|2016.0|   4.0| 692.0| 692.0|    XXX|20573.0|   null|   null|   null|  37.0|    2.0|  1.0|    null|    null| null|      T|   null|      U|   null| 1979.0|10282016|  null|  null|   null| 1.897628485E9| null|      B2|\n",
      "|  7.0|2016.0|   4.0| 254.0| 276.0|    ATL|20551.0|    1.0|     AL|   null|  25.0|    3.0|  1.0|20130811|     SEO| null|      G|   null|      Y|   null| 1991.0|     D/S|     M|  null|   null|  3.73679633E9|00296|      F1|\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  6.66643185E8|   93|      B2|\n",
      "| 16.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|  28.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1988.0|09302016|  null|  null|     AA|9.246846133E10|00199|      B2|\n",
      "| 17.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|   4.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 2012.0|09302016|  null|  null|     AA|9.246846313E10|00199|      B2|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_immigration_stats.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_immigration_stats.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "df_immigration_stats.write.mode('overwrite').parquet(\"sas_data\")\n",
    "df_immigration_stats=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Temperature dataset\n",
    "Lets check temperature data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#perform cleaning task here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dt                               8599212\n",
       "AverageTemperature               8235082\n",
       "AverageTemperatureUncertainty    8235082\n",
       "City                             8599212\n",
       "Country                          8599212\n",
       "Latitude                         8599212\n",
       "Longitude                        8599212\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dt                                object\n",
       "AverageTemperature               float64\n",
       "AverageTemperatureUncertainty    float64\n",
       "City                              object\n",
       "Country                           object\n",
       "Latitude                          object\n",
       "Longitude                         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "First check latest available date in temperature data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2013-09-01'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp['dt'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Since it contains only data untill 2013, so date field can't be used to join with immigration data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Keep data only for United states only as i94 data is for united states only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_temp = df_temp[df_temp['Country']=='United States']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dt                               687289\n",
       "AverageTemperature               661524\n",
       "AverageTemperatureUncertainty    661524\n",
       "City                             687289\n",
       "Country                          687289\n",
       "Latitude                         687289\n",
       "Longitude                        687289\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Data reduces drastically after keeping data for united states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dt                                   0\n",
       "AverageTemperature               25765\n",
       "AverageTemperatureUncertainty    25765\n",
       "City                                 0\n",
       "Country                              0\n",
       "Latitude                             0\n",
       "Longitude                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Remove Nulls from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_temp=df_temp[df_temp.AverageTemperature.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### City and country can be the natural key for temparature showing average temparature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City              Country      \n",
       "Abilene           United States    16.892500\n",
       "Akron             United States     9.605076\n",
       "Albuquerque       United States    11.135264\n",
       "Alexandria        United States    11.918475\n",
       "Allentown         United States     9.523296\n",
       "Amarillo          United States    15.023386\n",
       "Anaheim           United States    16.124837\n",
       "Anchorage         United States    -2.301646\n",
       "Ann Arbor         United States     8.520341\n",
       "Antioch           United States    14.447987\n",
       "Arlington         United States    14.542532\n",
       "Arvada            United States     2.419405\n",
       "Atlanta           United States    14.436726\n",
       "Aurora            United States     9.423826\n",
       "Austin            United States    19.980095\n",
       "Bakersfield       United States    15.817692\n",
       "Baltimore         United States    11.918475\n",
       "Baton Rouge       United States    20.303142\n",
       "Beaumont          United States    20.018035\n",
       "Bellevue          United States     7.503998\n",
       "Berkeley          United States    14.447987\n",
       "Birmingham        United States    17.094218\n",
       "Boston            United States     7.341441\n",
       "Bridgeport        United States     9.994930\n",
       "Brownsville       United States    22.618926\n",
       "Buffalo           United States     7.726906\n",
       "Burbank           United States    15.878038\n",
       "Cambridge         United States     7.341441\n",
       "Cape Coral        United States    23.035940\n",
       "Carrollton        United States    18.062720\n",
       "                                     ...    \n",
       "Tacoma            United States     7.503998\n",
       "Tallahassee       United States    19.964984\n",
       "Tampa             United States    21.925673\n",
       "Tempe             United States    21.048769\n",
       "Thornton          United States     8.777836\n",
       "Thousand Oaks     United States    15.878038\n",
       "Toledo            United States     9.592642\n",
       "Toms River        United States    11.855869\n",
       "Topeka            United States    11.844997\n",
       "Torrance          United States    15.878038\n",
       "Tucson            United States    17.694843\n",
       "Tulsa             United States    15.093142\n",
       "Vallejo           United States    14.447987\n",
       "Vancouver         United States     9.762706\n",
       "Virginia Beach    United States    15.678856\n",
       "Visalia           United States    15.817692\n",
       "Waco              United States    18.542724\n",
       "Warren            United States     8.520341\n",
       "Washington        United States    11.918475\n",
       "Waterbury         United States     9.994930\n",
       "West Covina       United States    15.878038\n",
       "West Jordan       United States    10.177263\n",
       "West Valley City  United States    10.177263\n",
       "Westminster       United States     8.777836\n",
       "Wichita           United States    13.225388\n",
       "Wichita Falls     United States    16.485163\n",
       "Windsor           United States     8.520341\n",
       "Winston Salem     United States    14.418861\n",
       "Worcester         United States     7.341441\n",
       "Yonkers           United States     9.523296\n",
       "Name: AverageTemperature, Length: 248, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.groupby(['City','Country'])['AverageTemperature'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Demographics dataset\n",
    "check demographics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                      2891\n",
       "State                     2891\n",
       "Median Age                2891\n",
       "Male Population           2888\n",
       "Female Population         2888\n",
       "Total Population          2891\n",
       "Number of Veterans        2878\n",
       "Foreign-born              2878\n",
       "Average Household Size    2875\n",
       "State Code                2891\n",
       "Race                      2891\n",
       "Count                     2891\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                       object\n",
       "State                      object\n",
       "Median Age                float64\n",
       "Male Population           float64\n",
       "Female Population         float64\n",
       "Total Population            int64\n",
       "Number of Veterans        float64\n",
       "Foreign-born              float64\n",
       "Average Household Size    float64\n",
       "State Code                 object\n",
       "Race                       object\n",
       "Count                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                       0\n",
       "State                      0\n",
       "Median Age                 0\n",
       "Male Population            3\n",
       "Female Population          3\n",
       "Total Population           0\n",
       "Number of Veterans        13\n",
       "Foreign-born              13\n",
       "Average Household Size    16\n",
       "State Code                 0\n",
       "Race                       0\n",
       "Count                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Removing Nulls will not improve quality of data so skipping the step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### City,State and Race should be the natural key for demographics as it is unique combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [City, State, Median Age, Male Population, Female Population, Total Population, Number of Veterans, Foreign-born, Average Household Size, State Code, Race, Count]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics[df_demographics[['City', 'State','Race']].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Airport dataset\n",
    "check airport data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ident           55075\n",
       "type            55075\n",
       "name            55075\n",
       "elevation_ft    48069\n",
       "continent       27356\n",
       "iso_country     54828\n",
       "iso_region      55075\n",
       "municipality    49399\n",
       "gps_code        41030\n",
       "iata_code        9189\n",
       "local_code      28686\n",
       "coordinates     55075\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airports.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ident            object\n",
       "type             object\n",
       "name             object\n",
       "elevation_ft    float64\n",
       "continent        object\n",
       "iso_country      object\n",
       "iso_region       object\n",
       "municipality     object\n",
       "gps_code         object\n",
       "iata_code        object\n",
       "local_code       object\n",
       "coordinates      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airports.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Keep data only for United states only as i94 data is for united states only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_airports = df_airports[df_airports['iso_country']=='US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ident           22757\n",
       "type            22757\n",
       "name            22757\n",
       "elevation_ft    22518\n",
       "continent           1\n",
       "iso_country     22757\n",
       "iso_region      22757\n",
       "municipality    22655\n",
       "gps_code        20984\n",
       "iata_code        2019\n",
       "local_code      21236\n",
       "coordinates     22757\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airports.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Keeping only US data halved the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ident               0\n",
       "type                0\n",
       "name                0\n",
       "elevation_ft      239\n",
       "continent       22756\n",
       "iso_country         0\n",
       "iso_region          0\n",
       "municipality      102\n",
       "gps_code         1773\n",
       "iata_code       20738\n",
       "local_code       1521\n",
       "coordinates         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airports.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Since ident can't be used for joining with immigration data. so municipality, state is required as join with immigration data\n",
    "so null municipality should be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Check types of airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "balloonport          18\n",
       "closed             1326\n",
       "heliport           6265\n",
       "large_airport       170\n",
       "medium_airport      692\n",
       "seaplane_base       566\n",
       "small_airport     13720\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airports.groupby('type')['type'].count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "i94 port entry can be done by large_airport,medium_airport,small_airport\n",
    "so only these types should be kept in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airportType = ['large_airport', 'medium_airport', 'small_airport']\n",
    "df_airports = df_airports[df_airports['type'].isin(airportType)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ident           14582\n",
       "type            14582\n",
       "name            14582\n",
       "elevation_ft    14519\n",
       "continent           0\n",
       "iso_country     14582\n",
       "iso_region      14582\n",
       "municipality    14532\n",
       "gps_code        14183\n",
       "iata_code        1865\n",
       "local_code      14383\n",
       "coordinates     14582\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airports.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Filtering removed half of the records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### ident/airport code should be the natural key for demographics as it is unique combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ident, type, name, elevation_ft, continent, iso_country, iso_region, municipality, gps_code, iata_code, local_code, coordinates]\n",
       "Index: []"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airports[df_airports[['ident']].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Immigration stats dataset\n",
    "check imimigration stats data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration_stats.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      int64\n",
       "cicid         float64\n",
       "i94yr         float64\n",
       "i94mon        float64\n",
       "i94cit        float64\n",
       "i94res        float64\n",
       "i94port        object\n",
       "arrdate       float64\n",
       "i94mode       float64\n",
       "i94addr        object\n",
       "depdate       float64\n",
       "i94bir        float64\n",
       "i94visa       float64\n",
       "count         float64\n",
       "dtadfile        int64\n",
       "visapost       object\n",
       "occup          object\n",
       "entdepa        object\n",
       "entdepd        object\n",
       "entdepu       float64\n",
       "matflag        object\n",
       "biryear       float64\n",
       "dtaddto        object\n",
       "gender         object\n",
       "insnum        float64\n",
       "airline        object\n",
       "admnum        float64\n",
       "fltno          object\n",
       "visatype       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immig.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Convert immigration data to table for sql query analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_immigration_stats.createOrReplaceTempView(\"immig_stats_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "check if cicid can be natural_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|cicid|count(1)|\n",
      "+-----+--------+\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check for duplicates\n",
    "spark.sql(\"\"\"\n",
    "SELECT cicid,count(1)\n",
    "FROM immig_stats_table\n",
    "group by cicid\n",
    "having count(1)>1\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+-------+------+------+-------+------+-----+--------+\n",
      "|cicid|i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear|dtaddto|gender|insnum|airline|admnum|fltno|visatype|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+-------+------+------+-------+------+-----+--------+\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+-------+------+------+-------+------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check for null values\n",
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM immig_stats_table\n",
    "where cicid is null\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "arrival and departure dates in immigration data set are relative with 1960-01-01. so it needs to be converted into proper date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+------------+--------------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|arrival_date|departure_date|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+------------+--------------+\n",
      "|5748517.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     CA|20582.0|  40.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1976.0|10292016|     F|  null|     QF|9.495387003E10|00011|      B1|  2016-04-30|    2016-05-08|\n",
      "|5748518.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     NV|20591.0|  32.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1984.0|10292016|     F|  null|     VA|9.495562283E10|00007|      B1|  2016-04-30|    2016-05-17|\n",
      "|5748519.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20582.0|  29.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1987.0|10292016|     M|  null|     DL|9.495640653E10|00040|      B1|  2016-04-30|    2016-05-08|\n",
      "|5748520.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20588.0|  29.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1987.0|10292016|     F|  null|     DL|9.495645143E10|00040|      B1|  2016-04-30|    2016-05-14|\n",
      "|5748521.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20588.0|  28.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1988.0|10292016|     M|  null|     DL|9.495638813E10|00040|      B1|  2016-04-30|    2016-05-14|\n",
      "|5748522.0|2016.0|   4.0| 245.0| 464.0|    HHW|20574.0|    1.0|     HI|20579.0|  57.0|    2.0|  1.0|20160430|     ACK| null|      G|      O|   null|      M| 1959.0|10292016|     M|  null|     NZ|9.498180283E10|00010|      B2|  2016-04-30|    2016-05-05|\n",
      "|5748523.0|2016.0|   4.0| 245.0| 464.0|    HHW|20574.0|    1.0|     HI|20586.0|  66.0|    2.0|  1.0|20160430|     ACK| null|      G|      O|   null|      M| 1950.0|10292016|     F|  null|     NZ|9.497968993E10|00010|      B2|  2016-04-30|    2016-05-12|\n",
      "|5748524.0|2016.0|   4.0| 245.0| 464.0|    HHW|20574.0|    1.0|     HI|20586.0|  41.0|    2.0|  1.0|20160430|     ACK| null|      G|      O|   null|      M| 1975.0|10292016|     F|  null|     NZ|9.497974673E10|00010|      B2|  2016-04-30|    2016-05-12|\n",
      "|5748525.0|2016.0|   4.0| 245.0| 464.0|    HOU|20574.0|    1.0|     FL|20581.0|  27.0|    2.0|  1.0|20160430|     ACK| null|      G|      O|   null|      M| 1989.0|10292016|     M|  null|     NZ|9.497324663E10|00028|      B2|  2016-04-30|    2016-05-07|\n",
      "|5748526.0|2016.0|   4.0| 245.0| 464.0|    LOS|20574.0|    1.0|     CA|20581.0|  26.0|    2.0|  1.0|20160430|     ACK| null|      G|      O|   null|      M| 1990.0|10292016|     F|  null|     NZ|9.501354793E10|00002|      B2|  2016-04-30|    2016-05-07|\n",
      "|5748527.0|2016.0|   4.0| 245.0| 504.0|    NEW|20574.0|    1.0|     MA|20576.0|  44.0|    2.0|  1.0|20160430|     GUZ| null|      G|      O|   null|      M| 1972.0|10292016|     M|  null|     UA|9.493828593E10|01215|      B2|  2016-04-30|    2016-05-02|\n",
      "|5748528.0|2016.0|   4.0| 245.0| 504.0|    LOS|20574.0|    1.0|   null|20575.0|  39.0|    2.0|  1.0|20160430|     GUZ| null|      G|      O|   null|      M| 1977.0|10292016|     M|  null|     CM|9.501810463E10|00472|      B2|  2016-04-30|    2016-05-01|\n",
      "|5748529.0|2016.0|   4.0| 245.0| 504.0|    WAS|20574.0|    1.0|     VA|20596.0|  38.0|    2.0|  1.0|20160430|     PNM| null|      G|      O|   null|      M| 1978.0|10292016|     M|  null|     CM|9.492489983E10|00488|      B2|  2016-04-30|    2016-05-22|\n",
      "|5748530.0|2016.0|   4.0| 245.0| 504.0|    LOS|20574.0|    1.0|     CA|20577.0|  56.0|    2.0|  1.0|20160430|     PNM| null|      G|      O|   null|      M| 1960.0|10292016|     F|  null|     CM|9.492648103E10|00302|      B2|  2016-04-30|    2016-05-03|\n",
      "|5748531.0|2016.0|   4.0| 245.0| 504.0|    LOS|20574.0|    1.0|     CA|20577.0|  38.0|    2.0|  1.0|20160430|     PNM| null|      G|      O|   null|      M| 1978.0|10282016|     M|  null|     CM|9.492629303E10|00302|      B2|  2016-04-30|    2016-05-03|\n",
      "|5748532.0|2016.0|   4.0| 245.0| 504.0|    MIA|20574.0|    1.0|     FL|20581.0|  53.0|    2.0|  1.0|20160430|     PNM| null|      G|      O|   null|      M| 1963.0|10292016|     F|  null|     CM|9.500640513E10|00430|      B2|  2016-04-30|    2016-05-07|\n",
      "|5748534.0|2016.0|   4.0| 245.0| 528.0|    SFR|20574.0|    1.0|     CA|   null|  84.0|    2.0|  1.0|20160430|     HNK| null|      G|   null|   null|   null| 1932.0|10282016|     F|  null|     CX|9.492476223E10|00872|      B2|  2016-04-30|          null|\n",
      "|5748876.0|2016.0|   4.0| 245.0| 582.0|    HOU|20574.0|    1.0|     TX|20583.0|  43.0|    1.0|  1.0|20160430|     GUZ| null|      G|      O|   null|      M| 1973.0|10292016|     M|  null|     UA|9.499463063E10|05574|      B1|  2016-04-30|    2016-05-09|\n",
      "|5748877.0|2016.0|   4.0| 245.0| 582.0|    HOU|20574.0|    1.0|     TX|20583.0|  30.0|    1.0|  1.0|20160430|     GUZ| null|      G|      O|   null|      M| 1986.0|10292016|     F|  null|     UA|9.499447663E10|05574|      B1|  2016-04-30|    2016-05-09|\n",
      "|5748881.0|2016.0|   4.0| 245.0| 582.0|    LOS|20574.0|    1.0|     CA|20575.0|  34.0|    2.0|  1.0|20160430|     SHG| null|      G|      O|   null|      M| 1982.0|10292016|     M|  null|     AM|9.496770903E10|00646|      B2|  2016-04-30|    2016-05-01|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_immigration_stats = spark.sql(\"\"\"SELECT *, \n",
    "                                 date_add(to_date('1960-01-01'), arrdate) AS arrival_date,\n",
    "                                 date_add(to_date('1960-01-01'), depdate) AS departure_date\n",
    "                                 FROM immig_stats_table\"\"\")\n",
    "df_immigration_stats.createOrReplaceTempView(\"immig_stats_table\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM immig_stats_table\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Check for distinct i94 ports and confirm if it matches with format with airports dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|i94port|\n",
      "+-------+\n",
      "|    FMY|\n",
      "|    BGM|\n",
      "|    HEL|\n",
      "|    DNS|\n",
      "|    MOR|\n",
      "|    FOK|\n",
      "|    HVR|\n",
      "|    SNA|\n",
      "|    PTK|\n",
      "|    CLG|\n",
      "|    SPM|\n",
      "|    OPF|\n",
      "|    DLB|\n",
      "|    ABS|\n",
      "|    NAS|\n",
      "|    MYR|\n",
      "|    PVD|\n",
      "|    OAK|\n",
      "|    FAR|\n",
      "|    OTT|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT distinct i94port\n",
    "FROM immig_stats_table\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Check for distinct visa type and see if visa_type.csv can be used as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|i94visa|visatype|\n",
      "+-------+--------+\n",
      "|    1.0|      B1|\n",
      "|    2.0|      WT|\n",
      "|    1.0|      E2|\n",
      "|    1.0|      I1|\n",
      "|    3.0|      M2|\n",
      "|    2.0|     CPL|\n",
      "|    1.0|      E1|\n",
      "|    3.0|      M1|\n",
      "|    3.0|      F1|\n",
      "|    1.0|     GMB|\n",
      "|    2.0|     GMT|\n",
      "|    2.0|      CP|\n",
      "|    3.0|      F2|\n",
      "|    1.0|      WB|\n",
      "|    1.0|       I|\n",
      "|    2.0|     SBP|\n",
      "|    2.0|      B2|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT distinct i94visa,visatype\n",
    "FROM immig_stats_table\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Check age of travellers(age at the time of entry) and take count by age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|  age|count(1)|\n",
      "+-----+--------+\n",
      "|  8.0|   14607|\n",
      "| 67.0|   32063|\n",
      "| 70.0|   24891|\n",
      "| 69.0|   28451|\n",
      "|  0.0|     765|\n",
      "|  7.0|   14233|\n",
      "|108.0|       2|\n",
      "| 88.0|     884|\n",
      "| 49.0|   56041|\n",
      "|101.0|       2|\n",
      "| 98.0|      26|\n",
      "| 29.0|   67762|\n",
      "|107.0|       1|\n",
      "| 64.0|   37002|\n",
      "| 75.0|   12305|\n",
      "| 47.0|   58127|\n",
      "| 42.0|   62150|\n",
      "| 44.0|   62001|\n",
      "| 35.0|   69626|\n",
      "| 62.0|   41352|\n",
      "+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT EXTRACT(year from arrival_date)-biryear as age,count(1)\n",
    "FROM immig_stats_table\n",
    "group by EXTRACT(year from arrival_date)-biryear\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "check for null values in immigration_stats data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+------+-----+--------+------------+--------------+\n",
      "|cicid|i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|  occup|entdepa|entdepd|entdepu|matflag|biryear|dtaddto|gender| insnum|airline|admnum|fltno|visatype|arrival_date|departure_date|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+------+-----+--------+------------+--------------+\n",
      "|    0|    0|     0|     0|     0|      0|      0|    239| 152592| 142457|   802|      0|    0|       1| 1881250|3088187|    238| 138429|3095921| 138429|    802|    477|414269|2982605|  83627|     0|19549|       0|           0|        142457|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+------+-----+--------+------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_immigration_stats.select([count(when(col(c).isNull(), c)).alias(c) for c in df_immigration_stats.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "gender has lots of null value so null values can be removed from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM immig_stats_table WHERE gender is not null\"\"\").createOrReplaceTempView(\"immig_stats_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|gender|count(1)|\n",
      "+------+--------+\n",
      "|     F| 1302743|\n",
      "|     M| 1377224|\n",
      "|     U|     467|\n",
      "|     X|    1610|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT gender,count(1)\n",
    "FROM immig_stats_table\n",
    "group by gender\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Data is analysed for outside traveller movement united states. The i94 data will serve as our fact table.\n",
    "Our **fact_immigration_stats** table will be :\n",
    "* cicid,\n",
    "* citizenship_country,\n",
    "* residence_country,\n",
    "* city, -> Joined with demographics and temperature table\n",
    "* state,\n",
    "* arrival_date, -> Joined with immig_date table\n",
    "* departure_date, -> Joined with immig_date table\n",
    "* age,\n",
    "* visa_type -> joined with vis_type table\n",
    "* airport_code -> joined with airports table\n",
    "\n",
    "\n",
    "\n",
    "**dim_immig_date** : Only date,month, year date is relevant for analysis\n",
    "* date, \n",
    "* month,\n",
    "* year\n",
    "\n",
    "**dim_airports**: refrential data for airport\n",
    "* ident,\n",
    "* airport_code,\n",
    "* type, \n",
    "* name, \n",
    "* elevation_ft, \n",
    "* state,\n",
    "* municipality, \n",
    "* iata_code\n",
    "\n",
    "**dim_demographics**: Data to check the demography of arrival city\n",
    "* City, \n",
    "* state, \n",
    "* median_age, \n",
    "* male_population, \n",
    "* female_population, \n",
    "* total population,\n",
    "* Average_Household_Size, \n",
    "* Race, \n",
    "* Count\n",
    "\n",
    "**dim_temperatures**: Analyse average temperature of cities with traveller arrivals \n",
    "\n",
    "* City,\n",
    "* average_temperature, \n",
    "* average_temperature_uncertainty \n",
    "\n",
    "**dim_visa_type**: Referential data for visa\n",
    "\n",
    "* visa_code,\n",
    "* visa_type, \n",
    "* visa_type_desc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### fact_immigration_stats:\n",
    "* Filter null gender data\n",
    "* convert arrival and departure dates\n",
    "* Drop rows where the mode of arrival is not air travel\n",
    "* Derive country of citizenship and country of residence from countries dictionary csv\n",
    "* compute age using birth year and year of our arrival date.\n",
    "* replace port of entry with city and state using i94 dictionary csv\n",
    "* keep only i94visa and rename it to visa_id and remove excess columns\n",
    "* insert data into immmigration_stats fact table\n",
    "* Write to parquet\n",
    "\n",
    "##### dim_temperature:\n",
    "* For the temperature table keep only united states data\n",
    "* Filter null temperature\n",
    "* Convert city to upper case\n",
    "* Remove date as it is not relevant for joining with fact data\n",
    "* get average temperature by city\n",
    "* Insert into the temperature table\n",
    "* Write to parquet\n",
    "\n",
    "##### dim_immig_date:\n",
    "* Get all the arrival dates from the immigration data_set;\n",
    "* extract year, month\n",
    "* insert into immig_date table\n",
    "* Write to parquet\n",
    "\n",
    "##### dim_airports:\n",
    "* Keep only USA data\n",
    "* Keep only data for airport based location like large_airport, medium_airport & small_airport\n",
    "* Filter null municipality data required for airport_codes\n",
    "* Insert to dim_airports table\n",
    "* Write to parquet\n",
    "\n",
    "##### dim_demographics:\n",
    "* Convert to city names to upper case\n",
    "* Insert to dim_demographics table\n",
    "* Write to parquet\n",
    "\n",
    "##### dim_visa_type:\n",
    "* get visa code and visa type desc from visa dictionary file\n",
    "* Extract visa_type and i94visa from i94 data\n",
    "* Merge data with dictionary tavle\n",
    "* Insert to dim_visa_type table\n",
    "* Write to parquet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Immigration Fact Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read i94 data\n",
    "df_immigration_stats=spark.read.parquet(\"sas_data\")\n",
    "df_countries = spark.read.option(\"header\",True).csv('countries.csv')\n",
    "df_i94port = spark.read.option(\"header\",True).csv('i94portCodes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create staging table\n",
    "df_immigration_stats.createOrReplaceTempView(\"immig_stats_table\")\n",
    "df_countries.createOrReplaceTempView(\"countries\")\n",
    "df_i94port.createOrReplaceTempView(\"port\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Filter null gender data\n",
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM immig_stats_table\n",
    "WHERE gender is not null\n",
    "\"\"\").createOrReplaceTempView(\"immig_stats_table\")\n",
    "\n",
    "#Filter null state port data\n",
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM port\n",
    "WHERE state is not null\n",
    "\"\"\").createOrReplaceTempView(\"port\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# convert arrival and departure dates\n",
    "spark.sql(\"\"\"SELECT *, \n",
    "                                 date_add(to_date('1960-01-01'), arrdate) AS arrival_date,\n",
    "                                 date_add(to_date('1960-01-01'), depdate) AS departure_date\n",
    "                                 FROM immig_stats_table\"\"\").createOrReplaceTempView(\"immig_stats_table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop rows where the mode of arrival is not air travel\n",
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM immig_stats_table\n",
    "WHERE i94mode = 1\n",
    "\"\"\").createOrReplaceTempView(\"immig_stats_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Derive country of citizenship from countries dictionary csv\n",
    "spark.sql(\"\"\"\n",
    "SELECT imm.*, \n",
    "citz.country as citizenship_country,\n",
    "res.country as residence_country\n",
    "FROM immig_stats_table imm, countries citz, countries res\n",
    "WHERE imm.i94cit=citz.code\n",
    "and imm.i94res=res.code\n",
    "\"\"\").createOrReplaceTempView(\"immig_stats_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# compute age using birth year and year of our arrival date.\n",
    "spark.sql(\"\"\"\n",
    "SELECT *,EXTRACT(year from arrival_date)-biryear as age\n",
    "FROM immig_stats_table\n",
    "\"\"\").createOrReplaceTempView(\"immig_stats_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# replace port of entry with city and state\n",
    "spark.sql(\"\"\"\n",
    "SELECT imm.*, \n",
    "loc.location AS entry_port_city,\n",
    "loc.state AS entry_port_state,\n",
    "loc.location || ', ' || loc.state as airport_code\n",
    "FROM immig_stats_table imm,port loc\n",
    "where imm.i94port = loc.code\n",
    "\"\"\").createOrReplaceTempView(\"immig_stats_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# keep only i94visa and rename it to visa_code and remove excess columns\n",
    "# Remove duplicates\n",
    "# insert data into immmigration_stats fact table\n",
    "df_immigration_stats_fact=spark.sql(\"\"\"\n",
    "SELECT DISTINCT\n",
    "cicid,\n",
    "citizenship_country,\n",
    "residence_country,\n",
    "entry_port_city,\n",
    "entry_port_state,\n",
    "arrival_date,\n",
    "departure_date,\n",
    "age,\n",
    "visatype as visa_type,\n",
    "airport_code as airport_code\n",
    "FROM immig_stats_table\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write to parquet\n",
    "df_immigration_stats_fact.write.partitionBy(\"entry_port_state\",\"entry_port_city\",\"airport_code\").mode('overwrite').parquet(\"output_data/fact_immigration_stats\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Temperature dimension load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read temperature data\n",
    "df_temp = spark.read.option(\"header\",True).csv('../../data2/GlobalLandTemperaturesByCity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create staging table\n",
    "df_temp.createOrReplaceTempView(\"temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# For the temperature table keep only united states data;\n",
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM temperature\n",
    "WHERE country='United States'\n",
    "\"\"\").createOrReplaceTempView(\"temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Filter null temperature \n",
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM temperature\n",
    "WHERE averagetemperature is not null\n",
    "\"\"\").createOrReplaceTempView(\"temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert city,country to upper case\n",
    "spark.sql(\"\"\"\n",
    "SELECT *, upper(city) as upper_city,upper(country) as upper_country\n",
    "FROM temperature\n",
    "\"\"\").createOrReplaceTempView(\"temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remove date as it is not relevant for joining with fact data\n",
    "# get average temperature by city,country\n",
    "spark.sql(\"\"\"\n",
    "select upper_city as city,\n",
    "upper_country as country,\n",
    "avg(averagetemperature) as average_temperature,\n",
    "avg(averagetemperatureuncertainty) as average_temperature_uncertainty\n",
    "FROM temperature\n",
    "group by upper_city,upper_country\n",
    "\"\"\").createOrReplaceTempView(\"temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Insert into the temperature table\n",
    "# Write to parquet\n",
    "\n",
    "df_temp_dim=spark.sql(\"\"\"\n",
    "SELECT \n",
    "*\n",
    "FROM temperature\n",
    "\"\"\")\n",
    "df_temp_dim.write.partitionBy(\"city\",\"country\").mode('overwrite').parquet(\"output_data/dim_temperature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Date Dimension Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get all the arrival dates from the immigration data_set\n",
    "# extract year, month\n",
    "# insert into immig_date table\n",
    "df_immig_date_dim=spark.sql(\"\"\"\n",
    "SELECT DISTINCT\n",
    "arrival_date as date,\n",
    "extract(month from arrival_date) as month,\n",
    "extract(year from arrival_date) as year\n",
    "FROM immig_stats_table\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write partition\n",
    "\n",
    "df_immig_date_dim.write.partitionBy(\"year\",\"month\").mode('overwrite').parquet(\"output_data/dim_immig_date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Airport dimension data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read Data\n",
    "df_airports = spark.read.option(\"header\",True).csv('airport-codes_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create staging table\n",
    "df_airports.createOrReplaceTempView(\"airports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Keep only USA data\n",
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM airports\n",
    "WHERE iso_country='US'\n",
    "\"\"\").createOrReplaceTempView(\"airports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Keep only data for airport based location like large_airport, medium_airport & small_airport\n",
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM airports\n",
    "WHERE municipality is not null\n",
    "\"\"\").createOrReplaceTempView(\"airports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Filter null municipality data required for airport_codes\n",
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM airports\n",
    "WHERE type in ('large_airport', 'medium_airport', 'small_airport')\n",
    "\"\"\").createOrReplaceTempView(\"airports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Insert to dim_airports table\n",
    "# Write to parquet\n",
    "df_airports_dim=spark.sql(\"\"\"\n",
    "SELECT DISTINCT\n",
    "ident,\n",
    "upper(municipality) || ', ' ||split(iso_region,'-')[1] as airport_code,\n",
    "type,\n",
    "name,\n",
    "iso_country as country\n",
    "FROM airports\n",
    "\"\"\")\n",
    "\n",
    "df_airports_dim.write.mode('overwrite').parquet(\"output_data/dim_airports\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Demographics dimension data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read Data\n",
    "df_demographics = spark.read.option(\"header\",True).option(\"delimiter\", ';').csv('us-cities-demographics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create staging table\n",
    "df_demographics.createOrReplaceTempView(\"demographics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# change city to upper case\n",
    "spark.sql(\"\"\"\n",
    "SELECT *, upper(city) as upper_city\n",
    "FROM demographics\n",
    "\"\"\").createOrReplaceTempView(\"demographics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Insert to dim_demographics table\n",
    "# Write to parquet\n",
    "df_demographics_dim=spark.sql(\"\"\"\n",
    "SELECT DISTINCT\n",
    "upper_city as city,\n",
    "state,\n",
    "`Median Age` as median_age,\n",
    "`Male Population` male_population,\n",
    "`Female Population` female_population,\n",
    "`Total Population` total_population,\n",
    "`Average Household Size` avg_household_size,\n",
    "Race,\n",
    "Count\n",
    "FROM demographics\n",
    "\"\"\")\n",
    "df_demographics_dim.write.mode('overwrite').parquet(\"output_data/dim_demographics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Visa type dimension data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read Data\n",
    "df_visa_dict = spark.read.option(\"header\",True).csv('visa_type.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create staging table\n",
    "df_visa_dict.createOrReplaceTempView(\"visa_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get visa code and visa type desc from visa dictionary file\n",
    "# Extract visa_type and i94visa from i94 data\n",
    "# Merge data with dictionary tavle\n",
    "spark.sql(\"\"\"\n",
    "SELECT vt.*,imm.visatype\n",
    "FROM visa_type vt, immig_stats_table imm\n",
    "where vt.visacode=imm.i94visa\n",
    "\"\"\").createOrReplaceTempView(\"visa_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Insert to dim_visa_type table\n",
    "# Write to parquet\n",
    "df_visa_type_dim=spark.sql(\"\"\"\n",
    "SELECT DISTINCT\n",
    "visacode as visa_code,\n",
    "visatype as visa_type,\n",
    "visacategory as visa_type_desc\n",
    "FROM visa_type\n",
    "\"\"\")\n",
    "df_visa_type_dim.write.mode('overwrite').parquet(\"output_data/dim_visa_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Read data from final tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-----------------+------------+--------------+----+---------+----------------+---------------+------------+\n",
      "|  cicid|citizenship_country|residence_country|arrival_date|departure_date| age|visa_type|entry_port_state|entry_port_city|airport_code|\n",
      "+-------+-------------------+-----------------+------------+--------------+----+---------+----------------+---------------+------------+\n",
      "| 2625.0|             POLAND|           POLAND|  2016-04-01|    2016-04-30|76.0|       B2|              NY|       NEW YORK|NEW YORK, NY|\n",
      "| 5859.0|             FRANCE|           FRANCE|  2016-04-01|    2016-04-15|12.0|       WT|              NY|       NEW YORK|NEW YORK, NY|\n",
      "| 5929.0|             FRANCE|           FRANCE|  2016-04-01|    2016-04-18|35.0|       WT|              NY|       NEW YORK|NEW YORK, NY|\n",
      "| 6030.0|             FRANCE|           FRANCE|  2016-04-01|    2016-04-04|20.0|       WT|              NY|       NEW YORK|NEW YORK, NY|\n",
      "| 6241.0|             FRANCE|           FRANCE|  2016-04-01|    2016-04-05|51.0|       WT|              NY|       NEW YORK|NEW YORK, NY|\n",
      "| 6569.0|             FRANCE|           FRANCE|  2016-04-01|    2016-04-06|24.0|       WT|              NY|       NEW YORK|NEW YORK, NY|\n",
      "| 6678.0|             FRANCE|           FRANCE|  2016-04-01|    2016-04-07|47.0|       WT|              NY|       NEW YORK|NEW YORK, NY|\n",
      "| 6889.0|             FRANCE|           FRANCE|  2016-04-01|    2016-04-08|36.0|       WT|              NY|       NEW YORK|NEW YORK, NY|\n",
      "| 7050.0|             FRANCE|           FRANCE|  2016-04-01|    2016-04-09|48.0|       WT|              NY|       NEW YORK|NEW YORK, NY|\n",
      "| 7517.0|             FRANCE|           FRANCE|  2016-04-01|    2016-04-18|11.0|       WT|              NY|       NEW YORK|NEW YORK, NY|\n",
      "| 7521.0|             FRANCE|           FRANCE|  2016-04-01|    2016-04-18|26.0|       WT|              NY|       NEW YORK|NEW YORK, NY|\n",
      "|14412.0|              ITALY|            ITALY|  2016-04-01|    2016-04-04|53.0|       WT|              NY|       NEW YORK|NEW YORK, NY|\n",
      "|14475.0|              ITALY|            ITALY|  2016-04-01|    2016-04-06|51.0|       WT|              NY|       NEW YORK|NEW YORK, NY|\n",
      "|14754.0|              ITALY|            ITALY|  2016-04-01|    2016-04-11|38.0|       WT|              NY|       NEW YORK|NEW YORK, NY|\n",
      "|19553.0|             NORWAY|           NORWAY|  2016-04-01|    2016-04-07|57.0|       WT|              NY|       NEW YORK|NEW YORK, NY|\n",
      "|19602.0|             NORWAY|           NORWAY|  2016-04-01|    2016-04-07|17.0|       WT|              NY|       NEW YORK|NEW YORK, NY|\n",
      "|21310.0|              SPAIN|            SPAIN|  2016-04-01|    2016-04-18|71.0|       WT|              NY|       NEW YORK|NEW YORK, NY|\n",
      "|21358.0|              SPAIN|            SPAIN|  2016-04-01|    2016-04-10|31.0|       WT|              NY|       NEW YORK|NEW YORK, NY|\n",
      "|23078.0|              SPAIN|   UNITED KINGDOM|  2016-04-01|    2016-04-05|18.0|       WT|              NY|       NEW YORK|NEW YORK, NY|\n",
      "|23229.0|              SPAIN|          MEXICO |  2016-04-01|    2016-04-04|53.0|       WT|              NY|       NEW YORK|NEW YORK, NY|\n",
      "+-------+-------------------+-----------------+------------+--------------+----+---------+----------------+---------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read immigration fact data\n",
    "df_immigration_stats_fact=spark.read.parquet(\"output_data/fact_immigration_stats\")\n",
    "df_immigration_stats_fact.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-----+\n",
      "|      date|year|month|\n",
      "+----------+----+-----+\n",
      "|2016-04-29|2016|    4|\n",
      "|2016-04-24|2016|    4|\n",
      "|2016-04-02|2016|    4|\n",
      "|2016-04-21|2016|    4|\n",
      "|2016-04-01|2016|    4|\n",
      "|2016-04-06|2016|    4|\n",
      "|2016-04-16|2016|    4|\n",
      "|2016-04-23|2016|    4|\n",
      "|2016-04-13|2016|    4|\n",
      "|2016-04-12|2016|    4|\n",
      "|2016-04-30|2016|    4|\n",
      "|2016-04-07|2016|    4|\n",
      "|2016-04-25|2016|    4|\n",
      "|2016-04-17|2016|    4|\n",
      "|2016-04-11|2016|    4|\n",
      "|2016-04-18|2016|    4|\n",
      "|2016-04-04|2016|    4|\n",
      "|2016-04-20|2016|    4|\n",
      "|2016-04-27|2016|    4|\n",
      "|2016-04-26|2016|    4|\n",
      "+----------+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read immigration date data\n",
    "df_immig_date_dim=spark.read.parquet(\"output_data/dim_immig_date\")\n",
    "df_immig_date_dim.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------------------+----------------+-------------+\n",
      "|average_temperature|average_temperature_uncertainty|            city|      country|\n",
      "+-------------------+-------------------------------+----------------+-------------+\n",
      "|  23.06892444289695|             1.1867802924791078|         HIALEAH|UNITED STATES|\n",
      "| 10.051168201978832|             1.2700310474240897|           OMAHA|UNITED STATES|\n",
      "| 18.062719999999995|             0.7863341935483864|        MESQUITE|UNITED STATES|\n",
      "|  14.43672555306185|             1.3709018916319313|         ATLANTA|UNITED STATES|\n",
      "| 10.177262800181238|             0.9249913910285453|WEST VALLEY CITY|UNITED STATES|\n",
      "|  9.777756186984398|             0.7787758936755294|          EUGENE|UNITED STATES|\n",
      "|  8.435723654886985|             1.3091483603947778|    GRAND RAPIDS|UNITED STATES|\n",
      "| 18.062719999999995|             0.7863341935483864|          DENTON|UNITED STATES|\n",
      "|  16.12483712696008|             0.7674734446130481|       ESCONDIDO|UNITED STATES|\n",
      "|  7.999159821712816|             1.3501375358166203|         MADISON|UNITED STATES|\n",
      "| 15.878038442083941|              0.797899342438036|       INGLEWOOD|UNITED STATES|\n",
      "|  14.44798735457766|             0.6754456246838646|         OAKLAND|UNITED STATES|\n",
      "|  19.96498351115425|             1.3486262528289679|     TALLAHASSEE|UNITED STATES|\n",
      "|  14.44798735457766|             0.6754456246838646|       SUNNYVALE|UNITED STATES|\n",
      "|  16.12483712696008|             0.7674734446130481|       SANTA ANA|UNITED STATES|\n",
      "| 16.382053970436562|             1.2175335166723988|     LITTLE ROCK|UNITED STATES|\n",
      "| 11.844996579247436|              1.070860889395666|          OLATHE|UNITED STATES|\n",
      "| 11.299415517794172|             1.3609166399487014|          DAYTON|UNITED STATES|\n",
      "| 15.817692463328274|              0.713710166919574|     BAKERSFIELD|UNITED STATES|\n",
      "| 15.994026611093268|             1.3768380891311283|        COLUMBIA|UNITED STATES|\n",
      "+-------------------+-------------------------------+----------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read temperature data\n",
    "df_temperature_dim=spark.read.parquet(\"output_data/dim_temperature\")\n",
    "df_temperature_dim.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+----------+---------------+-----------------+----------------+------------------+--------------------+------+\n",
      "|            city|       state|median_age|male_population|female_population|total_population|avg_household_size|                Race| Count|\n",
      "+----------------+------------+----------+---------------+-----------------+----------------+------------------+--------------------+------+\n",
      "|          FRESNO|  California|      30.0|         256130|           263942|          520072|              3.12|American Indian a...| 11380|\n",
      "|STERLING HEIGHTS|    Michigan|      39.6|          64985|            67077|          132062|              2.66|Black or African-...|  8054|\n",
      "|         TRENTON|  New Jersey|      33.3|          42581|            41650|           84231|              3.04|               Asian|  1437|\n",
      "|           CHICO|  California|      29.9|          46168|            44168|           90336|               2.5|  Hispanic or Latino| 15578|\n",
      "|       ELK GROVE|  California|      36.1|          80057|            86833|          166890|              3.34|American Indian a...|  2020|\n",
      "|       FULLERTON|  California|      34.5|          69549|            71300|          140849|              2.97|American Indian a...|  1668|\n",
      "|   SUNRISE MANOR|      Nevada|      32.5|          93505|            99103|          192608|              3.25|American Indian a...|  3962|\n",
      "|       PAWTUCKET|Rhode Island|      39.2|          36072|            35511|           71583|              2.41|  Hispanic or Latino| 16117|\n",
      "|     CHEEKTOWAGA|    New York|      40.7|          37476|            38599|           76075|               2.3|               Asian|  1584|\n",
      "|     JERSEY CITY|  New Jersey|      34.3|         131765|           132512|          264277|              2.57|               Asian| 67610|\n",
      "|           PLANO|       Texas|      38.1|         138565|           145054|          283619|              2.65|               Asian| 59958|\n",
      "|     CLARKSVILLE|   Tennessee|      29.7|          75029|            74161|          149190|              2.64|               White|104626|\n",
      "|           OGDEN|        Utah|      31.3|          44323|            41127|           85450|              2.68|               Asian|  1911|\n",
      "|          TUSTIN|  California|      33.4|          39511|            41052|           80563|              3.27|               White| 39660|\n",
      "|         HAMPTON|    Virginia|      35.5|          66214|            70240|          136454|              2.48|               White| 61753|\n",
      "|        KIRKLAND|  Washington|      40.8|          42159|            45108|           87267|               2.3|  Hispanic or Latino|  6720|\n",
      "|         OAKLAND|  California|      35.7|         203827|           215451|          419278|              2.56|American Indian a...|  8380|\n",
      "|         BRANDON|     Florida|      36.1|          55679|            58289|          113968|              2.64|               White| 80811|\n",
      "|     WESTMINSTER|    Colorado|      37.8|          54866|            58251|          113117|              2.63|               White|100084|\n",
      "|         SUNRISE|     Florida|      37.7|          41471|            51235|           92706|              2.98|               White| 54976|\n",
      "+----------------+------------+----------+---------------+-----------------+----------------+------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read demographics data\n",
    "df_demographics_dim=spark.read.parquet(\"output_data/dim_demographics\")\n",
    "df_demographics_dim.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------+-------------+--------------------+-------+\n",
      "|ident|    airport_code|         type|                name|country|\n",
      "+-----+----------------+-------------+--------------------+-------+\n",
      "| 01AL|     CLANTON, AL|small_airport| Ware Island Airport|     US|\n",
      "|  01U|   DUCKWATER, NV|small_airport|   Duckwater Airport|     US|\n",
      "| 0KY4|   OWENSBORO, KY|small_airport|       Cambron Field|     US|\n",
      "| 0LS5|     CANKTON, LA|small_airport|Trahan Ultralight...|     US|\n",
      "| 0MS8|      BENOIT, MS|small_airport|Catfish Point Air...|     US|\n",
      "| 0NK0| CATTARAUGUS, NY|small_airport|       Berdick Field|     US|\n",
      "| 19NY|     READING, NY|small_airport|Four Seasons Airport|     US|\n",
      "| 23NE|  STROMSBURG, NE|small_airport|Stromsburg Munici...|     US|\n",
      "| 28MO|      ROSCOE, MO|small_airport|      Pasley Airport|     US|\n",
      "| 2CA8|YUCCA VALLEY, CA|small_airport| B & E Ranch Airport|     US|\n",
      "| 2ND9|       NORMA, ND|small_airport|       Brekhus Field|     US|\n",
      "| 2NY0| SOUTH CAIRO, NY|small_airport|Catskill Valley A...|     US|\n",
      "| 2VG8|      WARSAW, VA|small_airport|  Folly Neck Airport|     US|\n",
      "| 33IS|     FINDLAY, IL|small_airport|      Howell Airport|     US|\n",
      "| 34OH| MARK CENTER, OH|small_airport|       Arend Airport|     US|\n",
      "| 3WI1| UNION GROVE, WI|small_airport|     Olson's Airport|     US|\n",
      "| 40KS|WILLIAMSBURG, KS|small_airport|      Chanay Airport|     US|\n",
      "|  49C|   CAMP LAKE, WI|small_airport|   Camp Lake Airport|     US|\n",
      "|  4C1| UNION MILLS, IN|small_airport|Flying U Ranch Ai...|     US|\n",
      "| 4IS1|      ATWOOD, IL|small_airport|        Kamm Airport|     US|\n",
      "+-----+----------------+-------------+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read airports data\n",
    "df_airports_dim=spark.read.parquet(\"output_data/dim_airports\")\n",
    "df_airports_dim.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------+\n",
      "|visa_code|visa_type|visa_type_desc|\n",
      "+---------+---------+--------------+\n",
      "|        2|      SBP|      Pleasure|\n",
      "|        2|      CPL|      Pleasure|\n",
      "|        1|      GMB|      Business|\n",
      "|        1|       E1|      Business|\n",
      "|        2|       B2|      Pleasure|\n",
      "|        1|       I1|      Business|\n",
      "|        2|       WT|      Pleasure|\n",
      "|        1|       E2|      Business|\n",
      "|        1|       B1|      Business|\n",
      "|        3|       F1|       Student|\n",
      "|        3|       M1|       Student|\n",
      "|        3|       M2|       Student|\n",
      "|        2|      GMT|      Pleasure|\n",
      "|        3|       F2|       Student|\n",
      "|        1|       WB|      Business|\n",
      "|        1|        I|      Business|\n",
      "|        2|       CP|      Pleasure|\n",
      "+---------+---------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read demographics data\n",
    "df_visa_type_dim=spark.read.parquet(\"output_data/dim_visa_type\")\n",
    "df_visa_type_dim.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Check for null and duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# function to check null values\n",
    "def nullCheck(spark, table_list):\n",
    "    \"\"\"\n",
    "    Check null values\n",
    "    spark: spark context \n",
    "    table_list: table list along with column names for null check   \n",
    "    \"\"\"  \n",
    "    for table_name in table_list:\n",
    "        for column in table_list[table_name]:\n",
    "            records = spark.sql(f\"\"\"SELECT COUNT(1) as col_count FROM {table_name} WHERE {column} IS NULL\"\"\")\n",
    "            if records.head()[0] > 0:\n",
    "                raise ValueError(f\"!!!Data quality test FAILED and {table_name} contains {records.head()[0]} null values for {column} column!!!\")\n",
    "            else:\n",
    "                print(f\"Data quality test PASSED and {table_name} contains {records.head()[0]} null values for {column} column\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def duplicateCheck(spark, table_list):\n",
    "    \"\"\"\n",
    "    Check duplicate records\n",
    "    spark: spark context \n",
    "    table_list: table list along with column names for null check   \n",
    "    \"\"\"  \n",
    "    for table_name in table_list:\n",
    "        column_list=str(table_list[table_name])[1:-1].replace(\"'\",\"\")\n",
    "        records = spark.sql(f\"\"\"SELECT COUNT(1) as col_count FROM {table_name} \n",
    "                                         GROUP BY {column_list}\n",
    "                                         having count(1)>1\"\"\")\n",
    "        len_records=records.count()\n",
    "        \n",
    "        if len_records == 0:\n",
    "            print(f\"Data quality test PASSED and {table_name} doesn't contain duplicate records\")\n",
    "        else :\n",
    "            raise ValueError(f\"!!!Data quality test FAILED and {table_name} contains duplicate records!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create tables from dataframes\n",
    "df_immigration_stats_fact.createOrReplaceTempView(\"immig_stats_table\")\n",
    "df_immig_date_dim.createOrReplaceTempView(\"immig_date_table\")\n",
    "df_temperature_dim.createOrReplaceTempView(\"temperature\")\n",
    "df_demographics_dim.createOrReplaceTempView(\"demographics\")\n",
    "df_airports_dim.createOrReplaceTempView(\"airports\")\n",
    "df_visa_type_dim.createOrReplaceTempView(\"visa_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# List of tables along with the natural key\n",
    "table_list = { 'immig_stats_table' : ['cicid'],\n",
    "                   'immig_date_table':['date'],\n",
    "                   'temperature':['city','country'],\n",
    "                   'demographics': ['city','state','race'],\n",
    "                   'airports':['ident'],\n",
    "                   'visa_type':['visa_type']\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality test PASSED and immig_stats_table contains 0 null values for cicid column\n",
      "Data quality test PASSED and immig_date_table contains 0 null values for date column\n",
      "Data quality test PASSED and temperature contains 0 null values for city column\n",
      "Data quality test PASSED and temperature contains 0 null values for country column\n",
      "Data quality test PASSED and demographics contains 0 null values for city column\n",
      "Data quality test PASSED and demographics contains 0 null values for state column\n",
      "Data quality test PASSED and demographics contains 0 null values for race column\n",
      "Data quality test PASSED and airports contains 0 null values for ident column\n",
      "Data quality test PASSED and visa_type contains 0 null values for visa_type column\n"
     ]
    }
   ],
   "source": [
    "# Call function to check null value\n",
    "nullCheck(spark, table_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality test PASSED and immig_stats_table doesn't contain duplicate records\n",
      "Data quality test PASSED and immig_date_table doesn't contain duplicate records\n",
      "Data quality test PASSED and temperature doesn't contain duplicate records\n",
      "Data quality test PASSED and demographics doesn't contain duplicate records\n",
      "Data quality test PASSED and airports doesn't contain duplicate records\n",
      "Data quality test PASSED and visa_type doesn't contain duplicate records\n"
     ]
    }
   ],
   "source": [
    "# Call function to check duplicate value\n",
    "duplicateCheck(spark, table_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Check null in other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+-----------------+------------+--------------+---+---------+----------------+---------------+------------+\n",
      "|cicid|citizenship_country|residence_country|arrival_date|departure_date|age|visa_type|entry_port_state|entry_port_city|airport_code|\n",
      "+-----+-------------------+-----------------+------------+--------------+---+---------+----------------+---------------+------------+\n",
      "|    0|                  0|                0|           0|         97893|285|        0|               0|              0|           0|\n",
      "+-----+-------------------+-----------------+------------+--------------+---+---------+----------------+---------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Immigration stats table\n",
    "df_immigration_stats_fact.select([count(when(col(c).isNull(), c)).alias(c) for c in df_immigration_stats_fact.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-----+\n",
      "|date|year|month|\n",
      "+----+----+-----+\n",
      "|   0|   0|    0|\n",
      "+----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Immigration date table\n",
    "df_immig_date_dim.select([count(when(col(c).isNull(), c)).alias(c) for c in df_immig_date_dim.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------------------+----+-------+\n",
      "|average_temperature|average_temperature_uncertainty|city|country|\n",
      "+-------------------+-------------------------------+----+-------+\n",
      "|                  0|                              0|   0|      0|\n",
      "+-------------------+-------------------------------+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# temperature table\n",
    "df_temperature_dim.select([count(when(col(c).isNull(), c)).alias(c) for c in df_temperature_dim.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------------+-----------------+----------------+------------------+----+-----+\n",
      "|city|state|median_age|male_population|female_population|total_population|avg_household_size|Race|Count|\n",
      "+----+-----+----------+---------------+-----------------+----------------+------------------+----+-----+\n",
      "|   0|    0|         0|              3|                3|               0|                16|   0|    0|\n",
      "+----+-----+----------+---------------+-----------------+----------------+------------------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# demographics table\n",
    "df_demographics_dim.select([count(when(col(c).isNull(), c)).alias(c) for c in df_demographics_dim.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+----+----+-------+\n",
      "|ident|airport_code|type|name|country|\n",
      "+-----+------------+----+----+-------+\n",
      "|    0|           0|   0|   0|      0|\n",
      "+-----+------------+----+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# airports table\n",
    "df_airports_dim.select([count(when(col(c).isNull(), c)).alias(c) for c in df_airports_dim.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------+\n",
      "|visa_code|visa_type|visa_type_desc|\n",
      "+---------+---------+--------------+\n",
      "|        0|        0|             0|\n",
      "+---------+---------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# visa type table\n",
    "df_visa_type_dim.select([count(when(col(c).isNull(), c)).alias(c) for c in df_visa_type_dim.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Join fact and dimension tables to verify data and join values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+----+---------------+------------+-------------------+----------------+--------------------+--------------+\n",
      "|    cicid|citizenship_country| age|entry_port_city|arrival_year|average_temperature|total_population|        airport_name|visa_type_desc|\n",
      "+---------+-------------------+----+---------------+------------+-------------------+----------------+--------------------+--------------+\n",
      "| 435217.0|             POLAND|32.0|       NEW YORK|        2016|  9.523295607566514|         8550405|  La Guardia Airport|      Business|\n",
      "| 968273.0|         ARGENTINA |66.0|       NEW YORK|        2016|  9.523295607566514|         8550405|John F Kennedy In...|      Pleasure|\n",
      "|1159872.0|             FRANCE|12.0|       NEW YORK|        2016|  9.523295607566514|         8550405|  La Guardia Airport|      Pleasure|\n",
      "|1171896.0|              SPAIN|54.0|       NEW YORK|        2016|  9.523295607566514|         8550405|John F Kennedy In...|      Pleasure|\n",
      "|1201784.0|              JAPAN|60.0|       NEW YORK|        2016|  9.523295607566514|         8550405|John F Kennedy In...|      Pleasure|\n",
      "|1694957.0|         COSTA RICA|37.0|       NEW YORK|        2016|  9.523295607566514|         8550405|  La Guardia Airport|      Business|\n",
      "|1793987.0|        NETHERLANDS|40.0|       NEW YORK|        2016|  9.523295607566514|         8550405|                 JFK|      Pleasure|\n",
      "|1915491.0|            MEXICO |34.0|       NEW YORK|        2016|  9.523295607566514|         8550405|                 JFK|      Pleasure|\n",
      "|2184132.0|            CROATIA|46.0|       NEW YORK|        2016|  9.523295607566514|         8550405|  La Guardia Airport|      Pleasure|\n",
      "|2469561.0|             BRAZIL|47.0|       NEW YORK|        2016|  9.523295607566514|         8550405|  La Guardia Airport|      Pleasure|\n",
      "|2496613.0|        NETHERLANDS|34.0|       NEW YORK|        2016|  9.523295607566514|         8550405|  La Guardia Airport|      Pleasure|\n",
      "|2503106.0|             SWEDEN|25.0|       NEW YORK|        2016|  9.523295607566514|         8550405|John F Kennedy In...|      Pleasure|\n",
      "|2683161.0|              ITALY|33.0|       NEW YORK|        2016|  9.523295607566514|         8550405|John F Kennedy In...|      Pleasure|\n",
      "|2868240.0|            ECUADOR|41.0|       NEW YORK|        2016|  9.523295607566514|         8550405|  La Guardia Airport|      Pleasure|\n",
      "|3089407.0|             FRANCE|17.0|       NEW YORK|        2016|  9.523295607566514|         8550405|John F Kennedy In...|      Pleasure|\n",
      "|3540803.0|             ISRAEL|58.0|       NEW YORK|        2016|  9.523295607566514|         8550405|  La Guardia Airport|      Pleasure|\n",
      "|4042538.0|            HUNGARY|46.0|       NEW YORK|        2016|  9.523295607566514|         8550405|John F Kennedy In...|      Pleasure|\n",
      "|4680780.0|              ITALY|12.0|       NEW YORK|        2016|  9.523295607566514|         8550405|                 JFK|      Pleasure|\n",
      "|4699348.0|     UNITED KINGDOM|28.0|       NEW YORK|        2016|  9.523295607566514|         8550405|  La Guardia Airport|      Pleasure|\n",
      "|4999996.0|         ARGENTINA | 7.0|       NEW YORK|        2016|  9.523295607566514|         8550405|  La Guardia Airport|      Pleasure|\n",
      "+---------+-------------------+----+---------------+------------+-------------------+----------------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select distinct\n",
    "imm.cicid,\n",
    "imm.citizenship_country,\n",
    "imm.age,\n",
    "imm.entry_port_city,\n",
    "dt.year as arrival_year,\n",
    "temp.average_temperature,\n",
    "dem.total_population,\n",
    "air.name as airport_name,\n",
    "vt.visa_type_desc\n",
    "from immig_stats_table imm,\n",
    "immig_date_table dt,\n",
    "temperature temp,\n",
    "demographics dem,\n",
    "airports air,\n",
    "visa_type vt\n",
    "where 1=1\n",
    "and imm.arrival_date=dt.date\n",
    "and imm.entry_port_city=temp.city\n",
    "and imm.entry_port_city=dem.city\n",
    "and imm.airport_code=air.airport_code\n",
    "and imm.visa_type=vt.visa_type\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Sample Queries to answer reporting questions in scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+\n",
      "|  age_group|traveller_count|\n",
      "+-----------+---------------+\n",
      "|20-50 years|        1276098|\n",
      "| > 70 years|         107803|\n",
      "| 0-20 years|         243213|\n",
      "|50-70 years|         616956|\n",
      "|Age Unknown|            790|\n",
      "+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Age group of travellers\n",
    "spark.sql(\"\"\"select \n",
    "case when imm.age >0 and imm.age <=20\n",
    "then '0-20 years'\n",
    "when imm.age >20 and imm.age <=50\n",
    "then '20-50 years'\n",
    "when imm.age >50 and imm.age <=70\n",
    "then '50-70 years'\n",
    "when imm.age >70\n",
    "then '> 70 years'\n",
    "else 'Age Unknown'\n",
    "end as age_group,\n",
    "count(distinct imm.cicid) as traveller_count\n",
    "from immig_stats_table imm\n",
    "group by case when imm.age >0 and imm.age <=20\n",
    "then '0-20 years'\n",
    "when imm.age >20 and imm.age <=50\n",
    "then '20-50 years'\n",
    "when imm.age >50 and imm.age <=70\n",
    "then '50-70 years'\n",
    "when imm.age >70\n",
    "then '> 70 years'\n",
    "else 'Age Unknown'\n",
    "end\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------+\n",
      "|arrival_year|traveller_count|\n",
      "+------------+---------------+\n",
      "|        2016|        2244860|\n",
      "+------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Count of traveller during the year\n",
    "spark.sql(\"\"\"select \n",
    "dt.year as arrival_year,count(distinct imm.cicid) as traveller_count\n",
    "from immig_stats_table imm,\n",
    "immig_date_table dt\n",
    "where  1=1\n",
    "and imm.arrival_date=dt.date\n",
    "group by dt.year\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+-------------------+\n",
      "|entry_port_city|traveller_count|average_temperature|\n",
      "+---------------+---------------+-------------------+\n",
      "|        ORLANDO|         118089|  22.30260243667857|\n",
      "|       SAVANNAH|              1| 19.406439563962774|\n",
      "|   INDIANAPOLIS|            342| 11.228673933953177|\n",
      "|        ATLANTA|          56646| 14.436725553061898|\n",
      "|          MIAMI|         282233| 23.068924442897472|\n",
      "|        MEMPHIS|             37| 16.075406540557875|\n",
      "|        OAKLAND|           3059| 14.447987354577648|\n",
      "|       PORTLAND|           3834|  9.762706232813944|\n",
      "|      VANCOUVER|           7939|   9.76270623281393|\n",
      "|      ANCHORAGE|             81|-2.3016456107756658|\n",
      "|         DENVER|          12198|  8.777836262323202|\n",
      "|         LAREDO|            201|  21.85121503496502|\n",
      "|        PHOENIX|          29886| 21.048769050958402|\n",
      "|      BALTIMORE|           3125| 11.918474511061222|\n",
      "|        HOUSTON|          85620| 20.228964301075347|\n",
      "|   JACKSONVILLE|             21| 21.045303622956112|\n",
      "|      ROCHESTER|             63|  7.726905762496018|\n",
      "|         TUCSON|            206| 17.694842917251073|\n",
      "|     LONG BEACH|            108| 16.124837126960077|\n",
      "|      SANTA ANA|           1160|   16.1248371269601|\n",
      "+---------------+---------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Effect on temperature by immigration\n",
    "spark.sql(\"\"\"select \n",
    "imm.entry_port_city,count(distinct imm.cicid) as traveller_count,\n",
    "avg(temp.average_temperature) as average_temperature\n",
    "from immig_stats_table imm,\n",
    "temperature temp\n",
    "where 1=1\n",
    "and imm.entry_port_city=temp.city\n",
    "group by imm.entry_port_city\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------+--------------------+----------------+\n",
      "|arrival_year|entry_port_city|                race|total_population|\n",
      "+------------+---------------+--------------------+----------------+\n",
      "|        2016|WEST PALM BEACH|               White|        106782.0|\n",
      "|        2016|          OMAHA|American Indian a...|        443887.0|\n",
      "|        2016|    ALBUQUERQUE|American Indian a...|        559131.0|\n",
      "|        2016|     SACRAMENTO|Black or African-...|        490715.0|\n",
      "|        2016|        NORFOLK|               Asian|        246393.0|\n",
      "|        2016|     FORT MYERS|               White|         74015.0|\n",
      "|        2016|      SANTA ANA|               Asian|        335423.0|\n",
      "|        2016|       NEW YORK|               Asian|       8550405.0|\n",
      "|        2016|    LOS ANGELES|               Asian|       3971896.0|\n",
      "|        2016|      BALTIMORE|               White|        621849.0|\n",
      "|        2016|      PITTSBURG|               White|         69427.0|\n",
      "|        2016|  SAN FRANCISCO|  Hispanic or Latino|        864816.0|\n",
      "|        2016|      CLEVELAND|               Asian|        388059.0|\n",
      "|        2016|      PITTSBURG|American Indian a...|         69427.0|\n",
      "|        2016|        MCALLEN|Black or African-...|        140253.0|\n",
      "|        2016|     GREENVILLE|Black or African-...|         90588.0|\n",
      "|        2016|     MANCHESTER|               Asian|        110223.0|\n",
      "|        2016|     BIRMINGHAM|               Asian|        214911.0|\n",
      "|        2016|        PHOENIX|American Indian a...|       1563001.0|\n",
      "|        2016|         LAREDO|               White|        255789.0|\n",
      "+------------+---------------+--------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Effect on race,population and demographics of port of entry cities\n",
    "spark.sql(\"\"\"select\n",
    "dt.year as arrival_year,\n",
    "imm.entry_port_city,\n",
    "dem.race,\n",
    "avg(dem.total_population) as total_population\n",
    "from immig_stats_table imm,\n",
    "immig_date_table dt,\n",
    "demographics dem\n",
    "where 1=1\n",
    "and imm.arrival_date=dt.date\n",
    "and imm.entry_port_city=dem.city\n",
    "group by \n",
    "dt.year,\n",
    "imm.entry_port_city,\n",
    "dem.race\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+---------------+\n",
      "|arrival_year|visa_type_desc|traveller_count|\n",
      "+------------+--------------+---------------+\n",
      "|        2016|       Student|          34445|\n",
      "|        2016|      Business|         345716|\n",
      "|        2016|      Pleasure|        1864699|\n",
      "+------------+--------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Count of travellers by different visa type\n",
    "spark.sql(\"\"\"select \n",
    "dt.year as arrival_year,\n",
    "vt.visa_type_desc,\n",
    "count(distinct imm.cicid) as traveller_count\n",
    "from immig_stats_table imm,\n",
    "immig_date_table dt,\n",
    "visa_type vt\n",
    "where 1=1\n",
    "and imm.arrival_date=dt.date\n",
    "and imm.visa_type=vt.visa_type\n",
    "group by dt.year,vt.visa_type_desc\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+---------------+--------------------+---------------+\n",
      "|arrival_year|arrival_month|entry_port_city|        airport_name|traveller_count|\n",
      "+------------+-------------+---------------+--------------------+---------------+\n",
      "|        2016|            4|        DETROIT|Detroit Metropoli...|          21047|\n",
      "|        2016|            4|        SPOKANE|  Ox Meadows Airport|              1|\n",
      "|        2016|            4|       PORTLAND|Portland Hillsbor...|           3834|\n",
      "|        2016|            4|     WILMINGTON|Pettigrew Moore A...|             14|\n",
      "|        2016|            4|        CHICAGO|Chicago Midway In...|          95104|\n",
      "|        2016|            4|     SACRAMENTO| Mc Clellan Airfield|           2173|\n",
      "|        2016|            4|          MIAMI|Kendall-Tamiami E...|         282233|\n",
      "|        2016|            4|      NASHVILLE|     Triune Airfield|            686|\n",
      "|        2016|            4|    BROWNSVILLE|     Resaca Airstrip|            283|\n",
      "|        2016|            4|       OROVILLE|       Dickson Field|              2|\n",
      "|        2016|            4|     SACRAMENTO|       Lauppes Strip|           2173|\n",
      "|        2016|            4|          MINOT|      Sundre Airport|              1|\n",
      "|        2016|            4|        MEMPHIS|General Dewitt Sp...|             37|\n",
      "|        2016|            4|        HOUSTON|     Houston Airpark|          85620|\n",
      "|        2016|            4|    SAN ANTONIO|San Antonio Inter...|           6507|\n",
      "|        2016|            4|       NEW YORK|John F Kennedy In...|         355966|\n",
      "|        2016|            4|        CHICAGO|Chicago O'Hare In...|          95104|\n",
      "|        2016|            4|        DEL RIO|Rio Vista Ranch A...|              9|\n",
      "|        2016|            4|    LOS ANGELES|         23R Airport|         235419|\n",
      "|        2016|            4|  POINT ROBERTS|Point Roberts Air...|              2|\n",
      "+------------+-------------+---------------+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Average footfall by airports\n",
    "spark.sql(\"\"\"select \n",
    "dt.year as arrival_year,\n",
    "dt.month as arrival_month,\n",
    "imm.entry_port_city,\n",
    "air.name as airport_name,\n",
    "count(distinct imm.cicid) as traveller_count\n",
    "from immig_stats_table imm,\n",
    "immig_date_table dt,\n",
    "airports air\n",
    "where 1=1\n",
    "and imm.arrival_date=dt.date\n",
    "and imm.airport_code=air.airport_code\n",
    "group by dt.year,\n",
    "dt.month,\n",
    "imm.entry_port_city,\n",
    "air.name\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+---------------+\n",
      "|arrival_year|arrival_month|traveller_count|\n",
      "+------------+-------------+---------------+\n",
      "|        2016|            4|        2244860|\n",
      "+------------+-------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Travellers yearly and monthly trends\n",
    "spark.sql(\"\"\"select \n",
    "dt.year as arrival_year,\n",
    "dt.month as arrival_month,\n",
    "count(distinct imm.cicid) as traveller_count\n",
    "from immig_stats_table imm,\n",
    "immig_date_table dt\n",
    "where 1=1\n",
    "and imm.arrival_date=dt.date\n",
    "group by dt.year,\n",
    "dt.month\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.4 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Following data dictionaries are used to enrich data\n",
    "\n",
    "* countries.csv : table containing country codes based on I94_SAS_Labels_Descriptions.SAS file \n",
    " * Data Description\n",
    "    * Code -> Integer : Country code for i94 data\n",
    "    * Country -> String : Country name for corresponding code\n",
    "* i94portCodes.csv: table containing city codes based on I94_SAS_Labels_Descriptions.SAS file \n",
    " * Data Description\n",
    "    * Code -> String : 3 digit i94 port code\n",
    "    * Location -> String : City for i94 port code\n",
    "    * State -> String : State for i94 port code\n",
    "* visa_type.csv : table containing visa code and visa type desc based on I94_SAS_Labels_Descriptions.SAS file \n",
    " * Data Description\n",
    "    * visacode -> Integer : i94 visa code\n",
    "    * visacategory -> String : Visa category for i94 visa code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Based on sheer size of immigration data, sparks makes a good choice to process data efficiently and quickly\n",
    "* Data can be loaded daily so that to gauge daily footfall of airports and plan accordingly\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    "\n",
    "##### Data model selection criteria\n",
    "* Star schema is chosen for this table model with 1 fact table and rest as dimensions\n",
    "* The advantage is that the dimensions can be reused in other models as conformed dimensions\n",
    "* Master data can also be implemeted for dimension tables\n",
    "* Separate fact and dimension data load can be done achieved with this data model\n",
    "* The trade off can be performance if it is compared to data lake model like cassandra where the data is preprocessed\n",
    "* However cassandra lacks in other benefits above, which can be achieved through start schema\n",
    "\n",
    "##### Data increased by 100 x :\n",
    "\n",
    "* Data will be required to be partitioned by year and month as it grows. partitioning will help in performance of query\n",
    "* Partioning in parquet format is optimum solution as parquet compress the data and provide gain as well\n",
    "* S3 should be a good choice for storing parquet files as it is cheap and spectrum tables can be created over it using athena\n",
    "\n",
    "##### The pipelines would be run on a daily basis by 7 am every day:\n",
    "\n",
    "* Airflow should be a good choice for scheduling pipeline\n",
    "* Before scheduling, any dependencies should be identified and the task should be sequenced in correct order\n",
    "* A notification email will be sent after completion of airflow task and after that business can start using the report\n",
    "* Airflow is open source and free to use so it bring overall cost down\n",
    "* Airflow can run on the same ec2 instance for spyspark so it won't increase the cost\n",
    "##### The database needed to be accessed by 100+ people:\n",
    "\n",
    "* Creating the tables in redshift makes good choice, so that reporting tools like tableau can ingest data and cater multiple audience\n",
    "* Dimensions should be distributed on all nodes, so that it can be available for fact data on each node\n",
    "* Fact data should be distributed by cities as distribution key to improve performance\n",
    "* Users should be categorized into below categories and assinged respectively roles and permissions\n",
    " * Power user : read only access to direct tables and other tools like alteryz\n",
    " * Developer : read and write access to tables\n",
    " * Admin : Admin access to tables\n",
    " * General user : regular business user with no access to tables but access to reports and dashboards\n",
    "* Moving data into redhshift is cost effective as the charge is not on read or write operations. whereas in case of spectrum table data gets charged based on number of read write operations\n",
    "* Assigning security roles and groups would give extra control on resource usage and it can also be used to track usage and denying unwanted report access\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
